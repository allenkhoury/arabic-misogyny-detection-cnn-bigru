{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Structure\n",
        "- Data loading, cleaning and preprocessing\n",
        "- Dividing data into features, labels and test data\n",
        "- Tokenizing words\n",
        "- Baseline model\n",
        "- Advanced model using fasttext\n",
        "- Evaluate, testing with F1, precision, recall and confusion matrix\n",
        "- Predict on a few sentences with output\n",
        "- Appendix: Hypertuning grid search method"
      ],
      "metadata": {
        "id": "q0HcoiVk5XLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install emoji\n",
        "!pip install pyarabic\n",
        "!pip install gensim\n",
        "!pip install fasttext"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tbVN-51diKT",
        "outputId": "45a8df3f-3ca3-4d0b-f8f3-be31080ac177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting emoji\n",
            "  Downloading emoji-2.15.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading emoji-2.15.0-py3-none-any.whl (608 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m608.4/608.4 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: emoji\n",
            "Successfully installed emoji-2.15.0\n",
            "Collecting pyarabic\n",
            "  Downloading PyArabic-0.6.15-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from pyarabic) (1.17.0)\n",
            "Downloading PyArabic-0.6.15-py3-none-any.whl (126 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarabic\n",
            "Successfully installed pyarabic-0.6.15\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n",
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.3.tar.gz (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.4/73.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybind11>=2.2 (from fasttext)\n",
            "  Using cached pybind11-3.0.1-py3-none-any.whl.metadata (10.0 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from fasttext) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fasttext) (2.0.2)\n",
            "Using cached pybind11-3.0.1-py3-none-any.whl (293 kB)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.3-cp312-cp312-linux_x86_64.whl size=4498214 sha256=9827c75907ad8cf404cbba9afb570b8ab5260dfc6c3b31c2c60134ace3ca3914\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/27/95/a7baf1b435f1cbde017cabdf1e9688526d2b0e929255a359c6\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.3 pybind11-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import emoji\n",
        "import pyarabic.araby as araby\n",
        "import io\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Bidirectional, Conv1D, Dropout, Dense, GlobalMaxPooling1D, SpatialDropout1D, GRU, GlobalAveragePooling1D, Input, concatenate\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "from gensim.models import Word2Vec, KeyedVectors\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score"
      ],
      "metadata": {
        "id": "GElIKomFdeEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connecting to Google Drive and loading the Let-mi and ArMI datasets"
      ],
      "metadata": {
        "id": "0EfZdXV1lvXe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDlmmRpWrfx7",
        "outputId": "25e257a8-86a1-4bf2-bf67-46f3826ae5ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Connecting to my google drive as the dataset is on my drive.\n",
        "# You will have to request the dataset from the original authors\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "armi_dataset = '/content/drive/My Drive/final-project/ArMI2021_training.tsv'\n",
        "letmi_dataset = '/content/drive/My Drive/final-project/let-mi_train_part.csv'\n",
        "\n",
        "armi_test_features_dataset = '/content/drive/My Drive/final-project/ArMI2021_test.tsv'\n",
        "armi_test_label_dataset = '/content/drive/My Drive/final-project/ArMI2021_gold.tsv'\n",
        "\n",
        "df_armi = pd.read_csv(armi_dataset, sep='\\t')\n",
        "df_armi_test_features = pd.read_csv(armi_test_features_dataset, sep='\\t')\n",
        "df_armi_test_label = pd.read_csv(armi_test_label_dataset, sep='\\t')\n",
        "df_letmi = pd.read_csv(letmi_dataset)"
      ],
      "metadata": {
        "id": "PRCpqptesobG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data preprocessing\n",
        "- extract the text and misogyny columns from both datasets\n",
        "- concat both datasets into one unified dataset\n",
        "- Convert the values in misogyny column to 1 and 0\n",
        "- Same thing to the test dataset"
      ],
      "metadata": {
        "id": "UOyzWhRI5zf6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get only text and misogyny from datasets\n",
        "df_armi = df_armi[['text', 'misogyny']]\n",
        "df_letmi = df_letmi[['text', 'misogyny']]\n",
        "\n",
        "# Concat both let-mi and ArMI into one dataset\n",
        "df = pd.concat([df_armi, df_letmi])\n",
        "\n",
        "# Now I am doing the same thing on the testing dataset that I got from ArMI\n",
        "df_armi_test_features = df_armi_test_features[['text']]\n",
        "df_armi_test_label = df_armi_test_label[['misogyny']]\n",
        "\n",
        "# Convert misogyny from 'none' and 'misogyny' to 0 and 1\n",
        "df['misogyny'] = (df['misogyny'] == 'misogyny').astype(int);\n",
        "df_armi_test_label['misogyny'] = (df_armi_test_label['misogyny'] == 'misogyny').astype(int);"
      ],
      "metadata": {
        "id": "x0NOnZ7h5ysX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95ypBtfhnxoT",
        "outputId": "e9f8922f-032d-4fe3-aa40-8bb1f990500e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Index: 13106 entries, 0 to 5239\n",
            "Data columns (total 2 columns):\n",
            " #   Column    Non-Null Count  Dtype \n",
            "---  ------    --------------  ----- \n",
            " 0   text      13106 non-null  object\n",
            " 1   misogyny  13106 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 307.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data cleaning\n",
        "This function will clean the data of both my training and testing datasets, it will be also used to clean the text that I will use to predict as a final experiment at the end. Details of this function are below in comments"
      ],
      "metadata": {
        "id": "dzpD4hT6mHaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def data_cleaning(text):\n",
        "\n",
        "  # For any foreign language or for links\n",
        "  text = text.lower()\n",
        "\n",
        "  # Removing all mentions with @\n",
        "  text = re.sub(r\"@\\w+\", '', text)\n",
        "\n",
        "  # Remove all links\n",
        "  text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', \"\", text, flags=re.MULTILINE)\n",
        "\n",
        "  # These are some issues that couldnt be removed so I had to manually force remove them\n",
        "  for char in [\"مستخدم@\", \"#\", \"…\", \"RT\", \"\\ufffd\"]:\n",
        "    text = text.replace(char, \"\")\n",
        "\n",
        "  # Convert exclamation point and question mark into words, to give them more weight in the context\n",
        "  text = re.sub(r'!+', ' [EXCLAMATION] ', text)\n",
        "  text = re.sub(r'\\?+', ' [QUESTION] ', text)\n",
        "\n",
        "  # Removed some useless characters\n",
        "  chars_to_remove = r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~،؛؟ـ٪٫٬«»“”•·…﴾﴿〈〉°±÷×©®™€£¥¢]'\n",
        "  text = re.sub(chars_to_remove, ' ', text)\n",
        "\n",
        "  # I am keeping everything on one line\n",
        "  text = re.sub(r'[\\r\\n]+', ' ', text)\n",
        "\n",
        "  # Normalizing some letters to unify some words and match more words\n",
        "  text = re.sub(\"[إأآا]\", \"ا\", text)\n",
        "  text = re.sub(\"ى\", \"ي\", text)\n",
        "  text = re.sub(\"ؤ\", \"ء\", text)\n",
        "  text = re.sub(\"ئ\", \"ء\", text)\n",
        "  text = re.sub(\"ة\", \"ه\", text)\n",
        "  text = re.sub(\"گ\", \"ك\", text)\n",
        "\n",
        "  # Remove extra spaces\n",
        "  text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "  # This is for underscores inside hashtags, so I am converting the hashtag into words\n",
        "  text = text.replace(\"_\", \" \")\n",
        "\n",
        "  # Since I dont have much data, I am converting emojis into text to also give more context to sentences\n",
        "  text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
        "\n",
        "  # strip tashkeel and tatweel\n",
        "  text = araby.strip_tashkeel(text)\n",
        "  text = araby.strip_tatweel(text)\n",
        "\n",
        "  text = text.strip()\n",
        "  return text"
      ],
      "metadata": {
        "id": "03rWjMpxaIPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'] = df['text'].apply(data_cleaning)\n",
        "df_armi_test_features['text'] = df_armi_test_features['text'].apply(data_cleaning)"
      ],
      "metadata": {
        "id": "vTsDyoHAa2wb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Put everything into X_train, y_train, X_test and y_text so it will be easier for me to work with\n",
        "X_train = df['text']\n",
        "y_train = df['misogyny']\n",
        "X_test = df_armi_test_features['text']\n",
        "y_test = df_armi_test_label['misogyny']"
      ],
      "metadata": {
        "id": "FTuZMapVIILH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlpk9DCWsvvx",
        "outputId": "ac58a4a1-ab67-495f-a2f0-879e38d52572"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((13106,), (13106,), (1967,), (1967,))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Top 10k most frequent words\n",
        "max_words = 10000\n",
        "\n",
        "# mean is 11 and 95 percentile is 113, so there is a big gap between sentences, I went with 48 as a middle ground\n",
        "max_len = 48\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words)\n",
        "tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "X_train_seq = pad_sequences(tokenizer.texts_to_sequences(X_train), maxlen=max_len)\n",
        "X_test_seq = pad_sequences(tokenizer.texts_to_sequences(X_test), maxlen=max_len)"
      ],
      "metadata": {
        "id": "EjD2L6G5lTRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline model\n",
        "This baseline without any pretrained or libraries"
      ],
      "metadata": {
        "id": "jp1bHoPxoPyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    # Input Layer\n",
        "    Embedding(max_words, 128, input_shape=(max_len,)),\n",
        "\n",
        "    # CNN Layer\n",
        "    Conv1D(64, 5, activation='relu'),\n",
        "    GlobalMaxPooling1D(keepdims=True),\n",
        "\n",
        "    # LSTM Layers\n",
        "    Bidirectional(LSTM(64, return_sequences=True)),\n",
        "    Dropout(0.5),\n",
        "    Bidirectional(LSTM(32)),\n",
        "\n",
        "    # Dense Layers\n",
        "    Dense(16, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Rkb2oBr0QsCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "collapsed": true,
        "id": "eRijjyxQQxOf",
        "outputId": "222ceb46-9f56-4cdf-95bb-62c6b71112fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_25 (\u001b[38;5;33mEmbedding\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_25 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m41,024\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_25         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_31                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │        \u001b[38;5;34m66,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_30 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_32                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m41,216\u001b[0m │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │         \u001b[38;5;34m1,040\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_31 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv1d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,024</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ global_max_pooling1d_25         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_31                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">66,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_32                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,040</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,429,345\u001b[0m (5.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,429,345</span> (5.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,429,345\u001b[0m (5.45 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,429,345</span> (5.45 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stop = EarlyStopping(\n",
        "    monitor='val_accuracy',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_seq, y_train,\n",
        "    epochs=20,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[early_stop]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxfdHrnYQ7Au",
        "outputId": "72f35eea-17d3-43f9-be19-b1b855891337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 13ms/step - accuracy: 0.6317 - loss: 0.6057 - val_accuracy: 0.9169 - val_loss: 0.2015\n",
            "Epoch 2/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9368 - loss: 0.1776 - val_accuracy: 0.9802 - val_loss: 0.0559\n",
            "Epoch 3/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.9861 - loss: 0.0559 - val_accuracy: 0.9920 - val_loss: 0.0242\n",
            "Epoch 4/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 22ms/step - accuracy: 0.9943 - loss: 0.0280 - val_accuracy: 0.9943 - val_loss: 0.0131\n",
            "Epoch 5/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 11ms/step - accuracy: 0.9956 - loss: 0.0159 - val_accuracy: 0.9962 - val_loss: 0.0101\n",
            "Epoch 6/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9987 - loss: 0.0104 - val_accuracy: 0.9981 - val_loss: 0.0041\n",
            "Epoch 7/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.9962 - val_loss: 0.0107\n",
            "Epoch 8/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9964 - loss: 0.0213 - val_accuracy: 0.9989 - val_loss: 0.0026\n",
            "Epoch 9/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9978 - loss: 0.0099 - val_accuracy: 0.9981 - val_loss: 0.0040\n",
            "Epoch 10/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9970 - loss: 0.0129 - val_accuracy: 0.9977 - val_loss: 0.0095\n",
            "Epoch 11/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9980 - loss: 0.0100 - val_accuracy: 0.9992 - val_loss: 0.0021\n",
            "Epoch 12/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9986 - loss: 0.0085 - val_accuracy: 0.9992 - val_loss: 0.0017\n",
            "Epoch 13/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0057 - val_accuracy: 0.9989 - val_loss: 0.0018\n",
            "Epoch 14/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.9991 - loss: 0.0062 - val_accuracy: 0.9985 - val_loss: 0.0066\n",
            "Epoch 15/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9978 - loss: 0.0094 - val_accuracy: 0.9981 - val_loss: 0.0079\n",
            "Epoch 16/20\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9978 - loss: 0.0090 - val_accuracy: 0.9989 - val_loss: 0.0027\n",
            "Epoch 16: early stopping\n",
            "Restoring model weights from the end of the best epoch: 11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "test_loss, test_acc = model.evaluate(X_test_seq, y_test)\n",
        "print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGYUlYWIRzGd",
        "outputId": "fd938b16-e4f2-4c2e-cdb2-9d1e5e88776c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.4611 - loss: 6.4509\n",
            "\n",
            "Test Accuracy: 46.31%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Advanced model using fasttext\n",
        "Next, I will create a more advanced model using [fasttext](https://fasttext.cc/docs/en/crawl-vectors.html) (n-grams) and the arabic vector file to create a better embedding matrix.\n",
        "\n",
        "Since I am working with Google Colab, I will let the instance download and unzip the file directly."
      ],
      "metadata": {
        "id": "qLFuCGddqSyi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Arabic vectors (compressed .gz file)\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\n",
        "\n",
        "# Decompress the file\n",
        "!gunzip cc.ar.300.vec.gz\n",
        "\n",
        "# Check if the file is there\n",
        "!ls -lh cc.ar.300.vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMiQwejmGUwT",
        "outputId": "cdca989c-be62-4b13-fcc6-d05d53dbfca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-12-19 17:49:42--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 13.225.143.109, 13.225.143.99, 13.225.143.122, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|13.225.143.109|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1272365870 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ar.300.vec.gz’\n",
            "\n",
            "cc.ar.300.vec.gz    100%[===================>]   1.18G   236MB/s    in 11s     \n",
            "\n",
            "2025-12-19 17:49:53 (114 MB/s) - ‘cc.ar.300.vec.gz’ saved [1272365870/1272365870]\n",
            "\n",
            "-rw-r--r-- 1 root root 4.3G Jan 18  2019 cc.ar.300.vec\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_fasttext_vectors(fname, word_index, max_words):\n",
        "    # Read the .vec file that we just downloaded\n",
        "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "\n",
        "    # Initialize matrix\n",
        "    embedding_matrix = np.zeros((max_words, d))\n",
        "\n",
        "    for line in fin:\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        word = tokens[0]\n",
        "        if word in word_index:\n",
        "            idx = word_index[word]\n",
        "            if idx < max_words:\n",
        "                embedding_matrix[idx] = np.array(tokens[1:], dtype='float32')\n",
        "    return embedding_matrix\n",
        "\n",
        "# Get the embedding matrix\n",
        "embedding_matrix = load_fasttext_vectors('cc.ar.300.vec', tokenizer.word_index, max_words)"
      ],
      "metadata": {
        "id": "tjw12fomqOeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Input Layer, using an embedding dim of 300 and the embedding matric we created above, and max len of 48\n",
        "input_layer = Input(shape=(max_len,))\n",
        "x = Embedding(max_words, 300, weights=[embedding_matrix], input_shape=(max_len,), trainable=False)(input_layer)\n",
        "\n",
        "x = SpatialDropout1D(0.4)(x)\n",
        "\n",
        "# CNN Layer\n",
        "x = Conv1D(128, 5, activation='relu', kernel_regularizer=regularizers.l2(0.001))(x)\n",
        "\n",
        "# GRU Layers\n",
        "x = Bidirectional(GRU(64, return_sequences=True))(x) # Pass to pooling\n",
        "\n",
        "avg_pool = GlobalAveragePooling1D()(x)\n",
        "max_pool = GlobalMaxPooling1D()(x)\n",
        "merged = concatenate([avg_pool, max_pool])\n",
        "\n",
        "# Dense Layers\n",
        "x = Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.001))(merged)\n",
        "x = Dropout(0.3)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "my_model = Model(inputs=input_layer, outputs=output)\n",
        "\n",
        "my_model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvO5TfvXS-yx",
        "outputId": "60877c8f-a007-4564-ab5c-128b39e15528"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:100: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "my_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "7Z-_oUjPsdCR",
        "outputId": "31b79b59-60e2-4875-86e2-53de5d3905dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │  \u001b[38;5;34m3,000,000\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m300\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mSpatialDropout1D\u001b[0m)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │    \u001b[38;5;34m192,128\u001b[0m │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m44\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m74,496\u001b[0m │ conv1d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m16,448\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ spatial_dropout1d   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>)  │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">192,128</span> │ spatial_dropout1… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">44</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">74,496</span> │ conv1d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ global_max_pooling… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ global_max_pooli… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">16,448</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,283,137\u001b[0m (12.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,283,137</span> (12.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m283,137\u001b[0m (1.08 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">283,137</span> (1.08 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,000,000\u001b[0m (11.44 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,000,000</span> (11.44 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"my_model.keras\", save_best_only=True),\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_accuracy\",\n",
        "        restore_best_weights=True,\n",
        "        patience=5,\n",
        "        verbose=1,\n",
        "        mode=\"max\"\n",
        "    )\n",
        "]\n",
        "\n",
        "history = my_model.fit(\n",
        "    X_train_seq, y_train,\n",
        "    epochs=100,              # Set a high number, EarlyStopping will cut it short\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,   # Use 20% of training data for validation\n",
        "    callbacks=[callbacks]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMp4Bqmpab83",
        "outputId": "b643aed0-ef0a-466d-c44b-9fa5eae4595a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14ms/step - accuracy: 0.5837 - loss: 0.9251 - val_accuracy: 0.6937 - val_loss: 0.7938\n",
            "Epoch 2/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.7300 - loss: 0.7346 - val_accuracy: 0.7590 - val_loss: 0.6600\n",
            "Epoch 3/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7600 - loss: 0.6561 - val_accuracy: 0.7822 - val_loss: 0.6076\n",
            "Epoch 4/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7691 - loss: 0.6174 - val_accuracy: 0.8085 - val_loss: 0.5653\n",
            "Epoch 5/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.7772 - loss: 0.5840 - val_accuracy: 0.8299 - val_loss: 0.5294\n",
            "Epoch 6/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.7887 - loss: 0.5518 - val_accuracy: 0.8360 - val_loss: 0.5022\n",
            "Epoch 7/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8016 - loss: 0.5330 - val_accuracy: 0.8242 - val_loss: 0.5089\n",
            "Epoch 8/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8103 - loss: 0.5112 - val_accuracy: 0.8616 - val_loss: 0.4538\n",
            "Epoch 9/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8139 - loss: 0.4962 - val_accuracy: 0.8707 - val_loss: 0.4262\n",
            "Epoch 10/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.8313 - loss: 0.4643 - val_accuracy: 0.8715 - val_loss: 0.4077\n",
            "Epoch 11/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8399 - loss: 0.4487 - val_accuracy: 0.8814 - val_loss: 0.3944\n",
            "Epoch 12/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.8525 - loss: 0.4300 - val_accuracy: 0.8886 - val_loss: 0.3707\n",
            "Epoch 13/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.8521 - loss: 0.4158 - val_accuracy: 0.9001 - val_loss: 0.3488\n",
            "Epoch 14/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8703 - loss: 0.3922 - val_accuracy: 0.9035 - val_loss: 0.3325\n",
            "Epoch 15/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8792 - loss: 0.3721 - val_accuracy: 0.9214 - val_loss: 0.3206\n",
            "Epoch 16/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.8886 - loss: 0.3539 - val_accuracy: 0.9233 - val_loss: 0.2895\n",
            "Epoch 17/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.8965 - loss: 0.3417 - val_accuracy: 0.9352 - val_loss: 0.2820\n",
            "Epoch 18/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.8970 - loss: 0.3382 - val_accuracy: 0.9497 - val_loss: 0.2504\n",
            "Epoch 19/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.9064 - loss: 0.3181 - val_accuracy: 0.9523 - val_loss: 0.2413\n",
            "Epoch 20/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9097 - loss: 0.2998 - val_accuracy: 0.9477 - val_loss: 0.2448\n",
            "Epoch 21/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9215 - loss: 0.2762 - val_accuracy: 0.9569 - val_loss: 0.2149\n",
            "Epoch 22/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.2722 - val_accuracy: 0.9420 - val_loss: 0.2321\n",
            "Epoch 23/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9298 - loss: 0.2706 - val_accuracy: 0.9687 - val_loss: 0.1986\n",
            "Epoch 24/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 17ms/step - accuracy: 0.9308 - loss: 0.2520 - val_accuracy: 0.9733 - val_loss: 0.1869\n",
            "Epoch 25/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9302 - loss: 0.2557 - val_accuracy: 0.9710 - val_loss: 0.1777\n",
            "Epoch 26/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9408 - loss: 0.2306 - val_accuracy: 0.9767 - val_loss: 0.1642\n",
            "Epoch 27/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9476 - loss: 0.2236 - val_accuracy: 0.9764 - val_loss: 0.1551\n",
            "Epoch 28/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9397 - loss: 0.2316 - val_accuracy: 0.9821 - val_loss: 0.1540\n",
            "Epoch 29/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9492 - loss: 0.2147 - val_accuracy: 0.9828 - val_loss: 0.1382\n",
            "Epoch 30/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9446 - loss: 0.2158 - val_accuracy: 0.9844 - val_loss: 0.1504\n",
            "Epoch 31/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9529 - loss: 0.2016 - val_accuracy: 0.9786 - val_loss: 0.1550\n",
            "Epoch 32/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9539 - loss: 0.1951 - val_accuracy: 0.9889 - val_loss: 0.1382\n",
            "Epoch 33/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 19ms/step - accuracy: 0.9535 - loss: 0.1945 - val_accuracy: 0.9897 - val_loss: 0.1269\n",
            "Epoch 34/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.9549 - loss: 0.1960 - val_accuracy: 0.9870 - val_loss: 0.1337\n",
            "Epoch 35/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9583 - loss: 0.1817 - val_accuracy: 0.9901 - val_loss: 0.1177\n",
            "Epoch 36/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 15ms/step - accuracy: 0.9579 - loss: 0.1852 - val_accuracy: 0.9897 - val_loss: 0.1197\n",
            "Epoch 37/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9574 - loss: 0.1876 - val_accuracy: 0.9886 - val_loss: 0.1207\n",
            "Epoch 38/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.9628 - loss: 0.1700 - val_accuracy: 0.9916 - val_loss: 0.1112\n",
            "Epoch 39/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 18ms/step - accuracy: 0.9645 - loss: 0.1721 - val_accuracy: 0.9855 - val_loss: 0.1148\n",
            "Epoch 40/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9609 - loss: 0.1688 - val_accuracy: 0.9905 - val_loss: 0.1076\n",
            "Epoch 41/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 12ms/step - accuracy: 0.9627 - loss: 0.1707 - val_accuracy: 0.9916 - val_loss: 0.1074\n",
            "Epoch 42/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9633 - loss: 0.1734 - val_accuracy: 0.9912 - val_loss: 0.1032\n",
            "Epoch 43/100\n",
            "\u001b[1m328/328\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.1612 - val_accuracy: 0.9905 - val_loss: 0.1042\n",
            "Epoch 43: early stopping\n",
            "Restoring model weights from the end of the best epoch: 38.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model\n",
        "test_loss, test_acc = my_model.evaluate(X_test_seq, y_test)\n",
        "print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8AiBUelahsT",
        "outputId": "65086640-126d-4a8f-9b88-77865dfacf0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8140 - loss: 0.6220\n",
            "\n",
            "Test Accuracy: 83.22%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate, testing with F1, precision, recall and confusion matrix\n",
        "Next we will evaluate our models and run some tests"
      ],
      "metadata": {
        "id": "3e55HL63s5eX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_probs = my_model.predict(X_test_seq)\n",
        "y_pred = (y_pred_probs > 0.5).astype(\"int32\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Precision\n",
        "precision = precision_score(y_test, y_pred)\n",
        "\n",
        "# Recall\n",
        "recall = recall_score(y_test, y_pred)\n",
        "\n",
        "# F1 score\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Corrected Precision: {precision:.4f}\")\n",
        "print(f\"Corrected Recall: {recall:.4f}\")\n",
        "print(f\"Corrected F1-score: {f1:.4f}\")"
      ],
      "metadata": {
        "id": "bYsM5crEtH8P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9272da6-2263-45b4-a1eb-bba0a6e3bac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.81      0.79       766\n",
            "           1       0.88      0.84      0.86      1201\n",
            "\n",
            "    accuracy                           0.83      1967\n",
            "   macro avg       0.82      0.83      0.83      1967\n",
            "weighted avg       0.83      0.83      0.83      1967\n",
            "\n",
            "Corrected Precision: 0.8771\n",
            "Corrected Recall: 0.8435\n",
            "Corrected F1-score: 0.8599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Confusion matrix"
      ],
      "metadata": {
        "id": "Dp8lYZKitNNy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Neutral', 'Misogyny'], yticklabels=['Neutral', 'Misogyny'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.title('Misogyny Detection Confusion Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "d5kI-khoIykn",
        "outputId": "1d984b5d-4a75-48e5-82fa-0ef4cf2cdfae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict on a few sentences with output\n",
        "I will run a small final test with a few sentence and let the model output the results of its predictions"
      ],
      "metadata": {
        "id": "IL9TPOautTM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_tweets = [\n",
        "    # Misogynistic (Class 1)\n",
        "    \"المرأة مكانها المطبخ ولا يجب أن تشارك في القرارات السياسية\", # Traditional sexism\n",
        "    \"يا فاشلة روحي اهتمي ببيتك أحسن من الصحافة\",               # Professional dismissal\n",
        "    \"النساء لا يمتلكن القدرة العقلية للقيادة، هن عاطفيات جداً\", # Biological fallacy\n",
        "    \"انتي مجرد وجه جميل ولا تفهمين شيئاً في هذا العلم\",        # Intellectual belittling\n",
        "    \"اسكتي يا بنت، الرجال هم من يتكلمون هنا\",                 # Direct silencing\n",
        "\n",
        "    # Polite / Neutral (Class 0)\n",
        "    \"تحية لكل امرأة عربية تكافح من أجل مستقبل وطنها\",          # Empowerment\n",
        "    \"الصحافة مهنة صعبة تتطلب الشجاعة من الجميع\",              # Neutral professional\n",
        "    \"يجب علينا احترام وجهات النظر المختلفة في هذا النقاش\",      # Neutral debate\n",
        "    \"شكراً لكِ على هذا المقال الرائع والمفيد جداً\",              # Appreciation\n",
        "    \"التعليم هو السلاح الأقوى لتغيير المجتمعات العربية\"          # General social\n",
        "]\n",
        "\n",
        "\n",
        "def predict_misogyny(sentences, model, tokenizer, max_len):\n",
        "    # Clean the sentences\n",
        "    cleaned_sentences = [data_cleaning(s) for s in sentences]\n",
        "\n",
        "    # Tokenize and Pad\n",
        "    sequences = tokenizer.texts_to_sequences(cleaned_sentences)\n",
        "    padded = pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "    # Predict\n",
        "    predictions = my_model.predict(padded)\n",
        "\n",
        "    # Output\n",
        "    for i, prob in enumerate(predictions):\n",
        "        label = \"MISOGYNY (1)\" if prob > 0.5 else \"NEUTRAL (0)\"\n",
        "        confidence = prob[0] if prob > 0.5 else 1 - prob[0]\n",
        "        print(f\"Tweet: {sentences[i]}\")\n",
        "        print(f\"Result: {label} | Confidence: {confidence*100:.2f}%\\n\")\n",
        "\n",
        "predict_misogyny(test_tweets, my_model, tokenizer, 48)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbwwEA1Zttkb",
        "outputId": "931fec2c-0bb2-45eb-f88c-8e1a96a3b4f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step\n",
            "Tweet: المرأة مكانها المطبخ ولا يجب أن تشارك في القرارات السياسية\n",
            "Result: MISOGYNY (1) | Confidence: 98.48%\n",
            "\n",
            "Tweet: يا فاشلة روحي اهتمي ببيتك أحسن من الصحافة\n",
            "Result: MISOGYNY (1) | Confidence: 99.80%\n",
            "\n",
            "Tweet: النساء لا يمتلكن القدرة العقلية للقيادة، هن عاطفيات جداً\n",
            "Result: NEUTRAL (0) | Confidence: 86.07%\n",
            "\n",
            "Tweet: انتي مجرد وجه جميل ولا تفهمين شيئاً في هذا العلم\n",
            "Result: MISOGYNY (1) | Confidence: 81.28%\n",
            "\n",
            "Tweet: اسكتي يا بنت، الرجال هم من يتكلمون هنا\n",
            "Result: MISOGYNY (1) | Confidence: 76.43%\n",
            "\n",
            "Tweet: تحية لكل امرأة عربية تكافح من أجل مستقبل وطنها\n",
            "Result: NEUTRAL (0) | Confidence: 99.94%\n",
            "\n",
            "Tweet: الصحافة مهنة صعبة تتطلب الشجاعة من الجميع\n",
            "Result: NEUTRAL (0) | Confidence: 98.64%\n",
            "\n",
            "Tweet: يجب علينا احترام وجهات النظر المختلفة في هذا النقاش\n",
            "Result: NEUTRAL (0) | Confidence: 94.96%\n",
            "\n",
            "Tweet: شكراً لكِ على هذا المقال الرائع والمفيد جداً\n",
            "Result: NEUTRAL (0) | Confidence: 99.86%\n",
            "\n",
            "Tweet: التعليم هو السلاح الأقوى لتغيير المجتمعات العربية\n",
            "Result: NEUTRAL (0) | Confidence: 76.80%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Appendix: Hypertuning grid search method\n",
        "\n",
        "This is the function I used to run a grid search for finding the best hyperparameter"
      ],
      "metadata": {
        "id": "-t8gundKtTlz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "learning_rates = [1e-3, 1e-4]\n",
        "dropout_rates = [0.3, 0.5]\n",
        "batch_sizes = [16, 32]\n",
        "\n",
        "results = []\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for dr in dropout_rates:\n",
        "        for bs in batch_sizes:\n",
        "            print(f\"Testing: LR={lr}, Dropout={dr}, Batch={bs}\")\n",
        "\n",
        "            input_layer = Input(shape=(max_len,))\n",
        "            x = Embedding(max_words, 300, weights=[embedding_matrix], trainable=False)(input_layer)\n",
        "            x = SpatialDropout1D(dr)(x)\n",
        "            x = Conv1D(128, 5, activation='relu')(x)\n",
        "            x = Bidirectional(GRU(64, return_sequences=True))(x)\n",
        "            avg_pool = GlobalAveragePooling1D()(x)\n",
        "            max_pool = GlobalMaxPooling1D()(x)\n",
        "            merged = concatenate([avg_pool, max_pool])\n",
        "            x = Dense(32, activation='relu')(merged)\n",
        "            x = Dropout(dr)(x)\n",
        "            output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "            m = Model(inputs=input_layer, outputs=output)\n",
        "            m.compile(optimizer=Adam(learning_rate=lr), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "            h = m.fit(X_train_seq, y_train,\n",
        "                      validation_split=0.2,\n",
        "                      epochs=30,\n",
        "                      batch_size=bs,\n",
        "                      callbacks=[EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)],\n",
        "                      verbose=0)\n",
        "\n",
        "            _, acc = m.evaluate(X_test_seq, y_test, verbose=0)\n",
        "            print(f\"Final Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "            results.append({'lr': lr, 'dropout': dr, 'batch': bs, 'accuracy': acc})\n",
        "\n",
        "rdf = pd.DataFrame(results).sort_values(by='accuracy', ascending=False)\n",
        "print(rdf)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwIlKduAOlX4",
        "outputId": "3d15d2b9-378e-43b7-8f81-172031327e54"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing: LR=0.001, Dropout=0.3, Batch=16\n",
            "Final Test Accuracy: 0.8246\n",
            "Testing: LR=0.001, Dropout=0.3, Batch=32\n",
            "Final Test Accuracy: 0.8302\n",
            "Testing: LR=0.001, Dropout=0.5, Batch=16\n",
            "Final Test Accuracy: 0.8165\n",
            "Testing: LR=0.001, Dropout=0.5, Batch=32\n",
            "Final Test Accuracy: 0.8353\n",
            "Testing: LR=0.0001, Dropout=0.3, Batch=16\n",
            "Final Test Accuracy: 0.8317\n",
            "Testing: LR=0.0001, Dropout=0.3, Batch=32\n",
            "Final Test Accuracy: 0.8221\n",
            "Testing: LR=0.0001, Dropout=0.5, Batch=16\n",
            "Final Test Accuracy: 0.8327\n",
            "Testing: LR=0.0001, Dropout=0.5, Batch=32\n",
            "Final Test Accuracy: 0.8353\n",
            "       lr  dropout  batch  accuracy\n",
            "3  0.0010      0.5     32  0.835282\n",
            "7  0.0001      0.5     32  0.835282\n",
            "6  0.0001      0.5     16  0.832740\n",
            "4  0.0001      0.3     16  0.831723\n",
            "1  0.0010      0.3     32  0.830198\n",
            "0  0.0010      0.3     16  0.824606\n",
            "5  0.0001      0.3     32  0.822064\n",
            "2  0.0010      0.5     16  0.816472\n"
          ]
        }
      ]
    }
  ]
}